# Change Data Capture (CDC) - E-Commerce Microservices

## ğŸ“š What is Change Data Capture (CDC)?

**Change Data Capture (CDC)** is a design pattern that identifies and captures changes made to data in a database and delivers those changes in real-time to downstream systems. Instead of polling databases or making synchronous API calls, CDC listens to the database transaction log (binlog in MySQL) and propagates changes automatically.

### Key Concepts

#### **How CDC Works:**
1. **Database Changes** â†’ Any INSERT, UPDATE, DELETE operation
2. **Transaction Log** â†’ MySQL binlog records all changes
3. **CDC Connector** â†’ Debezium reads the binlog
4. **Event Stream** â†’ Changes published to Kafka topics
5. **Consumers** â†’ Other services react to changes

#### **Benefits:**
- âœ… **Real-time data synchronization** - Changes propagate in milliseconds
- âœ… **Low latency** - No polling delays
- âœ… **Minimal overhead** - Reads transaction logs, doesn't query tables
- âœ… **Guaranteed delivery** - No data loss
- âœ… **Event sourcing** - Complete audit trail of all changes
- âœ… **Decoupling** - Services don't need direct database access

#### **CDC vs Traditional Approaches:**

| Aspect | CDC | API Calls | Database Polling |
|--------|-----|-----------|------------------|
| Latency | Milliseconds | Seconds | Minutes |
| Database Load | Minimal | Medium | High |
| Reliability | High | Medium | Low |
| Scalability | Excellent | Good | Poor |
| Complexity | Medium | Low | Low |

## ğŸ—ï¸ Project Architecture

This project implements a **real-world e-commerce scenario** with three microservices communicating via CDC:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Order Service  â”‚      â”‚ Inventory Serviceâ”‚      â”‚ Billing Service â”‚
â”‚   (Port 8081)   â”‚      â”‚   (Port 8082)    â”‚      â”‚   (Port 8083)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚                         â”‚
         â”‚ MySQL Binlog           â”‚ MySQL Binlog            â”‚ MySQL Binlog
         â–¼                        â–¼                         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Debezium â”‚             â”‚Debezium â”‚              â”‚Debezium â”‚
    â”‚Connectorâ”‚             â”‚Connectorâ”‚              â”‚Connectorâ”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚                       â”‚                        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚  Kafka   â”‚
                           â”‚ (Port    â”‚
                           â”‚  9092)   â”‚
                           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                      â”‚                        â”‚
         â–¼                      â–¼                        â–¼
  order-created          inventory-updated       billing-updated
  order-updated                                        
  order-deleted
```

### **Data Flow:**

1. **Order Created** (POST `/api/orders`)
   - Order Service: Creates order â†’ MySQL INSERT â†’ Debezium captures
   - Debezium: Publishes to `order-created` topic
   - Inventory Service: Consumes event â†’ Reserves inventory
   - Inventory change â†’ Debezium captures â†’ Publishes to `inventory-updated`
   - Billing Service: Consumes event â†’ Creates invoice

2. **Invoice Payment** (POST `/api/billing/invoice/{orderId}/pay`)
   - Billing Service: Marks invoice as PAID â†’ MySQL UPDATE â†’ Debezium captures
   - Debezium: Publishes to `billing-updated` topic
   - Order Service: Consumes event â†’ Updates order status to PAID

## ğŸ› ï¸ Technology Stack

- **Spring Boot 3.2.0** - Microservices framework
- **Debezium 2.5.0** - CDC connector
- **Apache Kafka 3.7.0** - Event streaming platform
- **MySQL 8.0** - Database with binlog
- **Maven** - Build tool
- **Lombok** - Boilerplate reduction

## ğŸ“‹ Prerequisites

1. **Java 17** or higher
2. **Maven 3.8+**
3. **MySQL 8.0** running on `localhost:3306`
   - Username: `root`
   - Password: `root`
4. **Kafka 3.7.0** at `D:\kafka_2.13-3.7.0`

## âš™ï¸ Setup Instructions

### Step 1: Enable MySQL Binlog (REQUIRED for CDC)

CDC requires MySQL binary logging to be enabled. Add the following to your MySQL configuration file:

**Windows:** `C:\ProgramData\MySQL\MySQL Server 8.0\my.ini`
**Linux/Mac:** `/etc/mysql/my.cnf`

```ini
[mysqld]
server-id=1
log_bin=mysql-bin
binlog_format=ROW
binlog_row_image=FULL
expire_logs_days=10
```

**Restart MySQL after making changes:**
```powershell
# Windows (Run as Administrator)
net stop MySQL80
net start MySQL80

# Linux/Mac
sudo systemctl restart mysql
```

**Verify binlog is enabled:**
```sql
SHOW VARIABLES LIKE 'log_bin';
-- Should show: log_bin = ON
```

### Step 2: Initialize Database

Run the SQL script to create databases and sample data:

```powershell
mysql -u root -p < scripts\mysql-init.sql
```

Or manually execute in MySQL Workbench/CLI.

### Step 3: Start Kafka

```powershell
# Start Kafka and Zookeeper
.\scripts\start-kafka.bat

# Wait 10-15 seconds, then create topics
.\scripts\create-topics.bat
```

**Verify topics created:**
```powershell
cd D:\kafka_2.13-3.7.0
bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092
```

You should see:
- `order-created`
- `order-updated`
- `order-deleted`
- `inventory-updated`
- `billing-updated`

### Step 4: Build the Project

```powershell
mvn clean install
```

### Step 5: Start Services

Open **3 separate terminals** and start each service:

**Terminal 1 - Order Service:**
```powershell
cd order-service
mvn spring-boot:run
```

**Terminal 2 - Inventory Service:**
```powershell
cd inventory-service
mvn spring-boot:run
```

**Terminal 3 - Billing Service:**
```powershell
cd billing-service
mvn spring-boot:run
```

**Service Ports:**
- Order Service: http://localhost:8081
- Inventory Service: http://localhost:8082
- Billing Service: http://localhost:8083

## ğŸ§ª Testing the CDC Flow

### Test Case 1: Complete Order Flow

#### Step 1: Create an Order
```powershell
curl -X POST http://localhost:8081/api/orders -H "Content-Type: application/json" -d "{\"customerId\":\"CUST-001\",\"productId\":\"PROD-001\",\"quantity\":2,\"totalAmount\":2000.00,\"status\":\"PENDING\"}"
```

**What happens:**
1. âœ… Order created in `order_db.orders` with status `PENDING`
2. âœ… Debezium captures INSERT â†’ Publishes to `order-created` topic
3. âœ… Inventory Service receives event â†’ Checks stock for PROD-001
4. âœ… If stock available (50 laptops):
   - Reserves 2 units
   - Creates record in `inventory_db.inventory` with status `RESERVED`
   - Updates `products.available_stock` from 50 â†’ 48
5. âœ… Debezium captures inventory INSERT â†’ Publishes to `inventory-updated` topic
6. âœ… Order Service receives event â†’ Updates order status to `INVENTORY_RESERVED`
7. âœ… Billing Service receives event â†’ Creates invoice in `billing_db.invoices`
8. âœ… Debezium captures invoice INSERT â†’ Publishes to `billing-updated` topic
9. âœ… Order Service receives event â†’ Updates order status to `BILLED`

#### Step 2: Verify Order Status
```powershell
curl http://localhost:8081/api/orders/1
```

**Expected Response:**
```json
{
  "id": 1,
  "customerId": "CUST-001",
  "productId": "PROD-001",
  "quantity": 2,
  "totalAmount": 2000.00,
  "status": "BILLED",
  "createdAt": "2025-10-25T07:14:40",
  "updatedAt": "2025-10-25T07:14:42"
}
```

#### Step 3: Check Inventory
```sql
USE inventory_db;
SELECT * FROM products WHERE product_id = 'PROD-001';
-- available_stock should be 48 (50 - 2)

SELECT * FROM inventory WHERE order_id = 1;
-- status should be 'RESERVED'
```

#### Step 4: Mark Invoice as Paid
```powershell
curl -X POST http://localhost:8083/api/billing/invoice/1/pay
```

**What happens:**
1. âœ… Invoice status updated to `PAID` in `billing_db.invoices`
2. âœ… Debezium captures UPDATE â†’ Publishes to `billing-updated` topic
3. âœ… Order Service receives event â†’ Updates order status to `PAID`

#### Step 5: Verify Final Order Status
```powershell
curl http://localhost:8081/api/orders/1
```

**Expected: status = "PAID"**

### Test Case 2: Insufficient Inventory

```powershell
# Try ordering 100 laptops (only 48 available now)
curl -X POST http://localhost:8081/api/orders -H "Content-Type: application/json" -d "{\"customerId\":\"CUST-002\",\"productId\":\"PROD-001\",\"quantity\":100,\"totalAmount\":200000.00,\"status\":\"PENDING\"}"
```

**Expected Flow:**
1. Order created with status `PENDING`
2. Inventory Service tries to reserve â†’ Fails (insufficient stock)
3. Inventory record created with status `FAILED`
4. Order Service updated to `INVENTORY_FAILED`
5. **No invoice created** (Billing Service only processes RESERVED inventory)

### Test Case 3: Monitor Kafka Topics

**Monitor order events:**
```powershell
cd D:\kafka_2.13-3.7.0
bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic order-created --from-beginning
```

**Monitor inventory events:**
```powershell
bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic inventory-updated --from-beginning
```

**Monitor billing events:**
```powershell
bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic billing-updated --from-beginning
```

## ğŸ“Š Database Schema

### Order Service (order_db)

**orders table:**
```sql
CREATE TABLE orders (
  id BIGINT PRIMARY KEY AUTO_INCREMENT,
  customer_id VARCHAR(255) NOT NULL,
  product_id VARCHAR(255) NOT NULL,
  quantity INT NOT NULL,
  total_amount DECIMAL(10,2) NOT NULL,
  status VARCHAR(50) NOT NULL,
  created_at TIMESTAMP NOT NULL,
  updated_at TIMESTAMP NOT NULL
);
```

### Inventory Service (inventory_db)

**inventory table:**
```sql
CREATE TABLE inventory (
  id BIGINT PRIMARY KEY AUTO_INCREMENT,
  order_id BIGINT NOT NULL,
  product_id VARCHAR(255) NOT NULL,
  quantity_reserved INT NOT NULL,
  available_quantity INT NOT NULL,
  status VARCHAR(50) NOT NULL,
  created_at TIMESTAMP NOT NULL,
  updated_at TIMESTAMP NOT NULL
);
```

**products table:**
```sql
CREATE TABLE products (
  product_id VARCHAR(50) PRIMARY KEY,
  product_name VARCHAR(255) NOT NULL,
  available_stock INT NOT NULL
);
```

### Billing Service (billing_db)

**invoices table:**
```sql
CREATE TABLE invoices (
  id BIGINT PRIMARY KEY AUTO_INCREMENT,
  order_id BIGINT NOT NULL,
  customer_id VARCHAR(255) NOT NULL,
  amount DECIMAL(10,2) NOT NULL,
  status VARCHAR(50) NOT NULL,
  created_at TIMESTAMP NOT NULL,
  updated_at TIMESTAMP NOT NULL
);
```

## ğŸ” Monitoring & Debugging

### Check Debezium Offset Files

Debezium tracks processed binlog positions in offset files:
```
offsets/
â”œâ”€â”€ order-offset.dat
â”œâ”€â”€ inventory-offset.dat
â””â”€â”€ billing-offset.dat
```

**To reset CDC (reprocess all events):**
```powershell
# Stop all services
# Delete offset files
Remove-Item offsets\*.dat
# Restart services
```

### Common Issues

#### 1. **Debezium can't connect to MySQL**
```
Error: Could not find first log file name in binary log index file
```

**Solution:** Enable binlog (see Step 1) and restart MySQL

#### 2. **Services can't connect to Kafka**
```
Error: Connection to node -1 (localhost/127.0.0.1:9092) could not be established
```

**Solution:** Ensure Kafka is running:
```powershell
cd D:\kafka_2.13-3.7.0
bin\windows\kafka-server-start.bat config\server.properties
```

#### 3. **Topics not found**
```
Error: Topic order-created not present in metadata
```

**Solution:** Create topics:
```powershell
.\scripts\create-topics.bat
```

## ğŸ“ Learning Points

### CDC Implementation Details

**Debezium Configuration:**
- Uses embedded Debezium engine in each service
- Reads MySQL binlog in real-time
- Publishes changes to Kafka topics
- Stores offset positions for fault tolerance

**Event Format:**
```json
{
  "operation": "c",  // c=create, u=update, d=delete
  "data": {
    "id": 1,
    "customer_id": "CUST-001",
    "status": "PENDING",
    ...
  }
}
```

### Microservices Communication

**Choreography Pattern:**
- Services react to events independently
- No central orchestrator
- Loose coupling
- High scalability

### Best Practices Demonstrated

1. âœ… **Idempotent consumers** - Services handle duplicate events
2. âœ… **Event versioning** - Operation type included in payload
3. âœ… **Offset management** - Debezium tracks processing position
4. âœ… **Error handling** - Failed inventory reservation doesn't block other services
5. âœ… **Separation of concerns** - Each service owns its database

## ğŸš€ Production Considerations

For production deployments, consider:

1. **Kafka Connect** instead of embedded Debezium
2. **Schema Registry** for event schema management
3. **Dead Letter Queues** for failed event processing
4. **Circuit breakers** for service resilience
5. **Distributed tracing** (Zipkin/Jaeger)
6. **Monitoring** (Prometheus/Grafana)
7. **High availability** - Multi-node Kafka cluster

## ğŸ“š Further Reading

- [Debezium Documentation](https://debezium.io/documentation/)
- [CDC Design Patterns](https://martinfowler.com/eaaDev/EventSourcing.html)
- [Kafka Streams](https://kafka.apache.org/documentation/streams/)
- [Event-Driven Architecture](https://www.confluent.io/blog/event-driven-architecture/)

## ğŸ“ Project Structure

```
change-data-capture/
â”œâ”€â”€ order-service/
â”‚   â”œâ”€â”€ src/main/java/com/systemdesign/order/
â”‚   â”‚   â”œâ”€â”€ entity/          # Order, OrderStatus
â”‚   â”‚   â”œâ”€â”€ repository/      # OrderRepository
â”‚   â”‚   â”œâ”€â”€ service/         # OrderService
â”‚   â”‚   â”œâ”€â”€ controller/      # OrderController
â”‚   â”‚   â”œâ”€â”€ config/          # DebeziumConfig
â”‚   â”‚   â””â”€â”€ listener/        # DebeziumListener, KafkaEventListener
â”‚   â””â”€â”€ pom.xml
â”œâ”€â”€ inventory-service/
â”‚   â”œâ”€â”€ src/main/java/com/systemdesign/inventory/
â”‚   â”‚   â”œâ”€â”€ entity/          # Inventory, Product, InventoryStatus
â”‚   â”‚   â”œâ”€â”€ repository/      # InventoryRepository, ProductRepository
â”‚   â”‚   â”œâ”€â”€ service/         # InventoryService
â”‚   â”‚   â”œâ”€â”€ config/          # DebeziumConfig
â”‚   â”‚   â””â”€â”€ listener/        # DebeziumListener, OrderEventListener
â”‚   â””â”€â”€ pom.xml
â”œâ”€â”€ billing-service/
â”‚   â”œâ”€â”€ src/main/java/com/systemdesign/billing/
â”‚   â”‚   â”œâ”€â”€ entity/          # Invoice, InvoiceStatus
â”‚   â”‚   â”œâ”€â”€ repository/      # InvoiceRepository
â”‚   â”‚   â”œâ”€â”€ service/         # BillingService
â”‚   â”‚   â”œâ”€â”€ controller/      # BillingController
â”‚   â”‚   â”œâ”€â”€ config/          # DebeziumConfig
â”‚   â”‚   â””â”€â”€ listener/        # DebeziumListener, InventoryEventListener
â”‚   â””â”€â”€ pom.xml
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ mysql-init.sql       # Database initialization
â”‚   â”œâ”€â”€ start-kafka.bat      # Kafka startup script
â”‚   â””â”€â”€ create-topics.bat    # Topic creation script
â”œâ”€â”€ offsets/                 # Debezium offset storage
â”œâ”€â”€ pom.xml                  # Parent POM
â””â”€â”€ README.md
```

## ğŸ‘¨â€ğŸ’» Author

System Design Learning Series - Change Data Capture Implementation

---

**Happy Learning! ğŸ‰**
